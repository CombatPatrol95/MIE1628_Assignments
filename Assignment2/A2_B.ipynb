{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqPzdjHRYyue"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiEcNGtiYyug",
        "outputId": "13efbe8e-ccc6-4443-c122-f2012a5c90d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| movieId   | rating   | userId   |\n",
            "|:----------|:---------|:---------|\n",
            "| 2         | 3        | 0        |\n",
            "| 3         | 1        | 0        |\n",
            "| 5         | 2        | 0        |\n",
            "| 9         | 4        | 0        |\n",
            "| 11        | 1        | 0        |\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1501 entries, 0 to 1500\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   movieId  1501 non-null   int64\n",
            " 1   rating   1501 non-null   int64\n",
            " 2   userId   1501 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 35.3 KB\n",
            "None\n",
            "\n",
            "Top 12 movies with highest ratings:\n",
            "\n",
            "| movieId   | rating   |\n",
            "|:----------|:---------|\n",
            "| 32        | 2.91667  |\n",
            "| 90        | 2.8125   |\n",
            "| 30        | 2.5      |\n",
            "| 94        | 2.47368  |\n",
            "| 23        | 2.46667  |\n",
            "| 49        | 2.4375   |\n",
            "| 29        | 2.4      |\n",
            "| 18        | 2.4      |\n",
            "| 52        | 2.35714  |\n",
            "| 62        | 2.25     |\n",
            "| 53        | 2.25     |\n",
            "| 92        | 2.21429  |\n",
            "\n",
            "Top 12 users who provided highest ratings:\n",
            "\n",
            "| userId   | rating   |\n",
            "|:---------|:---------|\n",
            "| 11       | 2.28571  |\n",
            "| 26       | 2.20408  |\n",
            "| 22       | 2.16071  |\n",
            "| 23       | 2.13462  |\n",
            "| 2        | 2.06522  |\n",
            "| 17       | 1.95652  |\n",
            "| 8        | 1.89796  |\n",
            "| 24       | 1.88462  |\n",
            "| 12       | 1.85455  |\n",
            "| 3        | 1.83333  |\n",
            "| 29       | 1.82609  |\n",
            "| 28       | 1.82     |\n"
          ]
        }
      ],
      "source": [
        "### 1st Question\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "df = pd.read_csv('movies.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# Print the column names and their data types\n",
        "print(df.info())\n",
        "\n",
        "# Calculate top 12 movies with highest ratings\n",
        "top_movies = df.groupby('movieId')['rating'].mean().sort_values(ascending=False).head(12)\n",
        "print(\"\\nTop 12 movies with highest ratings:\\n\")\n",
        "print(top_movies.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# Calculate top 12 users who provided highest ratings\n",
        "top_users = df.groupby('userId')['rating'].mean().sort_values(ascending=False).head(12)\n",
        "print(\"\\nTop 12 users who provided highest ratings:\\n\")\n",
        "print(top_users.to_markdown(numalign=\"left\", stralign=\"left\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9yJMA7GYyug"
      },
      "source": [
        "### Question 2 & 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYq-R4pWYyuh",
        "outputId": "33fa2740-f228-4b8b-a7fd-253776a17201",
        "vscode": {
          "languageId": "julia"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=2db71935a9ac0bd373c53994565bf9ef5811f744f4e80d24524ebb53ca80a6ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n",
            "RMSE (70/30 split): 2.2013052941111355\n",
            "MAE (70/30 split): 1.651832950880826\n",
            "RMSE (80/20 split): 1.8354844277682187\n",
            "MAE (80/20 split): 1.38034714297838\n"
          ]
        }
      ],
      "source": [
        "### 2nd Question\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Create a SparkSession (if not already created)\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
        "\n",
        "# Convert Pandas DataFrame to Spark DataFrame\n",
        "spark_df = spark.createDataFrame(df)\n",
        "\n",
        "# Create an ALS model\n",
        "als = ALS(\n",
        "    maxIter=5,\n",
        "    regParam=0.01,\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        ")\n",
        "\n",
        "# Split the data into training and test sets (70/30) randomly\n",
        "(training, test) = spark_df.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Train the model\n",
        "model = als.fit(training)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Evaluate the model (70/30)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "mae = evaluator.evaluate(predictions)\n",
        "\n",
        "# Split the data into training and test sets (80/20) randomly\n",
        "(training, test) = spark_df.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Train the model\n",
        "model = als.fit(training)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Evaluate the model (80/20)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse2 = evaluator.evaluate(predictions)\n",
        "evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "mae2 = evaluator.evaluate(predictions)\n",
        "\n",
        "# Print RMSE and MAE for both splits\n",
        "print(\"RMSE (70/30 split):\", rmse)\n",
        "print(\"MAE (70/30 split):\", mae)\n",
        "print(\"RMSE (80/20 split):\", rmse2)\n",
        "print(\"MAE (80/20 split):\", mae2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2raBBHQYyuh"
      },
      "source": [
        "### Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfjYLkyGYyuh",
        "outputId": "496b2ef5-9f92-4888-da0f-a45ada22910e",
        "vscode": {
          "languageId": "julia"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of best model: 0.7445522238261736\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"RecommendationSystemTuning\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "df = spark.read.csv(\"movies.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Split dataset into train and test sets (70/30)\n",
        "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Build the recommendation system with ALS\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        ")\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_grid = (\n",
        "    ParamGridBuilder()\n",
        "    .addGrid(als.rank, [10, 15, 20])\n",
        "    .addGrid(als.maxIter, [5, 10])\n",
        "    .addGrid(als.regParam, [0.01, 0.1, 0.2])\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# Define the evaluator which uses MAE\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
        ")\n",
        "\n",
        "# Cross validation with 5 folds\n",
        "crossval = CrossValidator(\n",
        "    estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5\n",
        ")\n",
        "\n",
        "# Train the model with 5-fold validation\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Get the model with best param combination\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "# Evaluate the best model\n",
        "mae = evaluator.evaluate(predictions)\n",
        "print(f\"MAE of best model: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmyq2J39Yyuh"
      },
      "source": [
        "### Question 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDG54aPFYyui",
        "outputId": "8bde1b36-86d8-45a9-d0e9-b724004a5ac9",
        "vscode": {
          "languageId": "julia"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                                                                                                                                            |\n",
            "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|10    |[{25, 2.2450678}, {92, 2.1650987}, {49, 2.1060581}, {89, 1.8897823}, {62, 1.8657926}, {42, 1.8157381}, {29, 1.5947124}, {31, 1.588448}, {47, 1.5870534}, {12, 1.5359523}, {32, 1.5212767}, {91, 1.5136149}]|\n",
            "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                                                                                                                                          |\n",
            "+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|12    |[{17, 3.9057534}, {55, 3.652953}, {46, 3.561054}, {27, 3.4551537}, {64, 3.4420598}, {32, 3.257344}, {94, 3.1105342}, {35, 3.0530741}, {90, 2.9822607}, {65, 2.9819922}, {23, 2.8218036}, {91, 2.8110683}]|\n",
            "+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendations\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "df = spark.read.csv(\"movies.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Split dataset into train and test (70/30)\n",
        "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Build the recommendation model using ALS\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        ")\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_grid = (\n",
        "    ParamGridBuilder()\n",
        "    .addGrid(als.rank, [10, 15, 20])\n",
        "    .addGrid(als.maxIter, [5, 10])\n",
        "    .addGrid(als.regParam, [0.01, 0.1, 0.2])\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# Define the evaluator\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
        ")\n",
        "\n",
        "# Create the cross-validator\n",
        "crossval = CrossValidator(\n",
        "    estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5\n",
        ")\n",
        "\n",
        "# Fit the model with the best parameters\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Get the best model\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Generate top 12 movie recommendations for user 10 and user 12\n",
        "user_recs = best_model.recommendForAllUsers(12)\n",
        "\n",
        "# Show the recommendations for user 10\n",
        "user_recs.filter(col(\"userId\") == 10).show(truncate=False)\n",
        "\n",
        "# Show the recommendations for user 12\n",
        "user_recs.filter(col(\"userId\") == 12).show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
